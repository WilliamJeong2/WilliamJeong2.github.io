[
{
	"uri": "https://williamjeong2.github.io/bioinformatics/paper-review/01-signatures-of-mutational-processes-in-human-cancer/",
	"title": "[논문요약]Signatures of mutational processes in human cancer",
	"tags": [],
	"description": "",
	"content": " 1. Mutational catalogues somatic mutations(체세포 돌연변이)의 유병률은 암 종류들 내에서 매우 다양하며, megabase(Mb) 당 0.001에서 400까지 다양하다. -\u0026gt;우리가 아는 자외선을 많이 쐬면 피부암 발병률이 높아지고, 흡연을 많이 하면 폐암 발병률이 높다는 것과 같이 만성 돌연변이 유발성 노출과 관련된 암은 가장 높은 유병률을 보여준다.\n2. The landscape of mutational signatures 원칙적으로 모든 종류의 mutations(substitutions, indels, rearrangements)와 모든 accessory matations들의 특성은 mutational signatures가 정의되는 특징들의 집합에 포함될 수 있다.\n염기 치환(base substitution)을 사용해서 mutational signatures을 추출하고 추가적으로 각각의 mutations의 서열 context에 대한 정보를 포함했다. 6가지 종류의 염기 치환(base substitution)-C\u0026gt;A, C\u0026gt;G, C\u0026gt;T, T\u0026gt;A, T\u0026gt;C, T\u0026gt;G-이 있고 5\u0026rsquo;과 3' 염기에 대한 정보를 각 mutation base에 통합하였기 때문에 96개의 mutations 분류가 가능하다. 이 96개의 substitution classification은 \u0026lsquo;동일한 substitution을 유발하지만 다른 서열 context에서 발생하는 mutational signatures을 구별\u0026rsquo;하는데 유용하게 사용한다.\nsubstitution mutation이 가능한 96개의 경우 중 1개 또는 2개만이 두드러지는 특징을 가지는 signatures가 있으며, 이는 mutation types 및 서열 context의 특이성을 보여준다. 대부분의 암 종에서 최소 2개의 mutational signatures가 관찰되었으며, liver, uterus and stomach에서 최대 6개가 관찰됨. 이러한 차이는 부분적으로 signatures 추출 능력의 차이에 원인이 있을수 있지만, 일부 암은 다른 암보다 더 복잡한 돌연변이 과정 레퍼토리를 가지고 있는 것으로 보여진다.\n3. Mutational signatures and age of cancer diagnosis signature 1A/B는 소아 및 성인 암 types의 대부분에서 age와 강한 상관관계를 보였다. 진단 연령과의 상관관계는 암 환자의 일생 동안 암 유전자의 1A/B 기질의 상당 부분이 다른 사람들(normal somatic tissues)과 비슷하게 일정한 비율로 발생된다는 가설과 일치한다.\n연령에 따른 모든 signatures에 대한 일관된 상관관계가 없다는 것은 이러한 signatures와 관련된 mutations이 다른 사람에서 다른 비율로 생성되었음을 시사한다. 아마도 다른 발암물질 노출의 결과 또는 neoplastic change가 시작된 후에 발생할 수 있다.\n4. Thus. numan cancer의 기초가 되는 somatic mutations의 과정의 다양성과 복잡성은 현재 암 genome에 묻혀있는 mutations의 패턴을 통해 밝혀지고 있다. 전체 genome 시퀀싱된 암의 수가 증가하고 분석방법이 더욱 개선됨에 따라 그 특징에 대한 보다 정확한 정의와 함께 더 많은 mutation signatures가 추출 될 가능성이 높다.\n Reference  Signatures of mutational processes in human cancer | Nature   "
},
{
	"uri": "https://williamjeong2.github.io/blog/1-extract-google-account-profile-picture/",
	"title": "구글 프로필 사진 다운로드하기",
	"tags": [],
	"description": "",
	"content": "구글 프로필 사진을 다운받아야 할 경우가 가끔 있다. 한글로 검색해보니 정보가 나오지 않아서 검색 결과의 내용을 정리해 두고자 한다.\n여러개의 구글 계정을 사용중이라면 CTRL + SHIFT + N 을 눌러 private window 를 하나 만든다.\n  프로필 사진을 다운받고자 하는 계정으로 gmail같은 구글 서비스를 로그인 한다. https://get.google.com/albumarchive 에 접속한다. 프로필 사진 \u0026gt; Profile Photos 으로 이동한다. 여기에서 계정의 모든 프로필 사진들을 찾을 수 있다. 우측 상단 구석에 있는 triple dot 버튼을 사용해서 하나의 사진을 다운받거나 모든 사진을 다운받을 수 있다.  "
},
{
	"uri": "https://williamjeong2.github.io/about/",
	"title": "About",
	"tags": [],
	"description": "",
	"content": "Jinwoo Jeong 정진우 Contact  jinwoo5480@snu.ac.kr   ⚡️ Interests  Bioinformatics Data Scientist Deep Learning   🏫 Educations and Research Experiences Master Student of BiKE Lab in Seoul National University\nEditing\u0026hellip;\n Stacks \n"
},
{
	"uri": "https://williamjeong2.github.io/blog/2-how-to-save-apple-time-machine-mackups-to-cloud-services/",
	"title": "맥 타임머신을 클라우드 서비스에 하기(원드라이브, 구글드라이브, 드랍박스 등)",
	"tags": [],
	"description": "",
	"content": " *이 글은 Lhyam Sumal의 HOW TO SAVE APPLE TIME MACHINE BACKUPS TO CLOUD SERVICES LIKE ONEDRIVE 를 번역한 글입니다. 모든 저작권과 권리는 Sumal에게 있습니다.\n*This article is a translated version of Lhyam Sumal\u0026rsquo;s article: HOW TO SAVE APPLE TIME MACHINE BACKUPS TO CLOUD SERVICES LIKE ONEDRIVE. All rights goes back to him.\n*제가 이해한 대로 번역하였기 때문에 완벽하지 않을 수 있습니다.\n 타임머신은 굉장한 기능이면서, 제 생각에는 macOS의 최고 기능입니다. 네, 윈도우에도 파일 히스토리가 있지만 타임머신만큼 포괄적인 것은 없습니다. 말 그대로 맥을 복원하고 프로그램을 다시 설치하거나 환경설정을 지정하거나 driver를 사용하지 않고도 이전에 중단한 위치를 정확하게 선택할 수 있습니다!\n그러나 백업하려면 외장하드가 연결되어야 합니다. 물론 2018년(원문이 쓰인 날)에는 클라우드 서비스에 백업할 수 있습니다. 저는 마이크로소프트 오피스 365를 구독해서 1TB의 공간을 가지고 있습니다. 문서, 사진, 음악, 비디오 및 데스크탑 폴더가 이미 원드라이브에 백업되는 반면에 내 프로그램들과 설정들은 어떤가요?\n놀랍게도 애플은 클라우드 서비스를 사용한 백업 옵션을 타임머신에서 제공하지 않습니다. 하지만 우리는 답을 찾을 것이다. 늘 그랬듯이..(의역)\n하지만 그렇게 열심히 찾아보지 않아도 되었습니다. 이전에 타임머신 백업을 네트워크 드라이브에 저장하는 방법을 약간의 수정을 통해서 할 수 있는 방법을 기사로 썼습니다. 다음은 타임머신을 원드라이브, 구글드라이브, 아이클라우드 또는 원하는 클라우드 서비스에 저장할 수 있는 방법입니다.\n어떻게 작동하는가? 이 글의 목적상 원드라이브를 사용하고 있지만 다른 클라우드 서비스도 동일한 방식으로 작동합니다. 맥에서 이미 클라우드 동기화 서비스를 사용하고 있다고 가정하면 다음 단계를 따르는 것이 매우 간단하며 몇 분 정도 걸립니다.\n가상 드라이브를 생성하여 클라우드 서비스에 저장한 다음 맥에 마운트 해야 합니다. 타임머신 설정을 약간 조정하면 맥에서 가상 드라이브를 인식하고 자동으로 저장을 시작합니다.\nmacOS가 변경 사항을 가상 드라이브에 저장할 때마다 원드라이브 앱은 해당 변경사항을 클라우드에 다시 동기화합니다.\n가상 드라이브 생성 가상 드라이브의 장점은 전체 1TB를 가상 드라이브에 할당된 공간으로 지정하더라도 실제 차지하는 공간은 그 안에 포함된 파일의 크기만큼만 됩니다.\n클라우드 드라이브 폴더 내에 디스크 이미지를 저장해야 합니다. 맥에서 원드라이브 폴더를 찾고 디스크 이미지를 여기에 저장했습니다.\n 디스크 유틸리티를 엽니다. 간단하게 Spotlight나 Alfred를 이용해 검색할 수 있습니다.- 파일 메뉴에서 새로운 이미지(New Image) \u0026gt; 빈 이미지(Black Image)를 선택합니다. (단축키 cmd+n) 클라우드 폴더를 찾아서 가상 드라이브 이름을 설정합니다. (MacBookTM)- 가상드라이브의 최대 용량을 입력합니다. 저의 경우 200 GB를 입력했습니다.- 포맷을 Mac OS 확장 (저널링)로 선택합니다. 암호화는 사용해도 되고 안 해도 되는데 사용한다면 128-bit 를 선택합니다. 그러면 암호를 입력하는 창이 뜨는데 복구할 때 사용하기 때문에 잊어버리면 안 됩니다. 파티션을 단일 파티션으로 설정합니다. 마지막으로 이미지 포맷을 분할 번들 디스크 이미지(sparse bundle disk image)로 선택합니다. 디스크 이미지 사이즈를 체크합니다. - 저의 경우 이미지 포맷을 변경하니까 사이즈가 기본으로 변경되어 다시 수정하였습니다.  완료하였다면 디스크 유틸리티를 종료 할 수 있습니다.\n가상 드라이브 마운트 저의 경우 자동으로 가상 드라이브가 마운트 되고 MacBookTM이 나타났습니다.\n자동으로 마운트 되지 않을 경우 파인더를 열고 디스크 이미지를 저장한 위치로 이동하여 두 번 클릭하면 됩니다.\n가상 드라이브를 인식하도록 타임머신 구성 이 파트는 조금 까다로워 보이지만 실제로는 간단합니다.\n  터미널을 엽니다. (저와 다른 창이 떠도 괜찮습니다.)\n  아래의 명령어를 입력합니다. 여기서 {mounted-disk-image}는 마운트 된 디스크의 이름입니다.\nsudo tmutil setdestination /Volumes/{mounted-disk-image} #저는 MacBookTimeMachine으로 했으니까 위의 이미지 처럼 입력하였습니다.   Enter를 누르세요.\n  비밀번호를 입력하라고 나오면 입력하고 Enter를 누르세요.\n  입력이 완료되면 exit를 눌러 터미널을 종료합니다.\n  타임머신 설정 거의 다 끝났습니다. 👏\n시스템 환경설정에서 타임머신을 열면 새로 만든 드라이브가 자동으로 나타납니다.\n타임머신에서 OneDrive 폴더 제외 이 부분은 권장하는 파트입니다. 그렇지 않으면 클라우드 동기화 폴더 포함하여 타임머신이 백업한 다음에 클라우드 동기화를 진행합니다.\n폴더를 제외하려면\n 타임머신 환경설정에서 옵션을 클릭합니다. + 아이콘을 클릭하고 클라우드 폴더를 선택합니다. (예: Onedrive 또는 googledrive) 저장을 클릭합니다.  그리고 당신은.. 타임머신이 가상드라이브 백업을 시작하고 원드라이브에 해당 변경 사항을 동기화할 것입니다. 더는 외장하드를 검색하거나 네트워크 서버 연결을 기다릴 필요가 없습니다.\n백업을 다운받기 위해서 조금 고통스럽겠지만 저를 믿으세요!\n 📝코멘트 백업을 진행하다 보면 매우 느린 속도에 좌절하게 되지만 이 속도를 개선해 줄 방법이 있습니다. 아래의 링크를 참고해주세요.\n 맥에서 타임머신 백업 시간을 크게 줄여주는 마법 같은 명령어  "
},
{
	"uri": "https://williamjeong2.github.io/bioinformatics/02-gene-expression-unit-explained/",
	"title": "RPKM, FPKM, TPM이 무엇인가?",
	"tags": [],
	"description": "",
	"content": "생물 정보학에서 굉장히 흔하게 접할 수 있는 용어 중 하나로 RPKM, FPKM, TPM이 있습니다.\nRNA-seq의 발현 분석에서 normalized gene expression을 의미하는 것으로 초창기에는 RPKM이 많이 쓰였으나 FPKM을 거쳐 현재에는 TPM을 주로 사용하고 있습니다. (FPKM 또한 많이 사용중)\n따라서 이 3가지 값을 계산하는 방법을 소개하려고 합니다. 아래 순서대로 이해하시면 됩니다.\n먼저 A, B, C, D라는 4개의 gene과 3개의 replicate를 가지고 있는 테이블이 있습니다. gene 옆에 있는 kb(kilobase)는 gene의 길이입니다.\n   Gene Name Rep1 Counts Rep2 Counts Rep3 Counts     A (2kb) 10 12 30   B (4kb) 20 25 60   C (1kb) 5 8 15   D (10kb) 0 0 1    Rep3를 보면 gene에 상관없이 다른 replicate들보다 많은 reads를 가진 것을 알 수 있습니다. 이는 sequencing depth가 다른 replicate들보다 높다는 걸 의미합니다. 이제 이걸 normalize(정규화) 할 것입니다.\n또한 gene B는 gene A에 2배에 해당하는 \u0026lsquo;길이\u0026rsquo;를 가지고 있고, 이건 replicate에 상관없이 2배 많은 reads를 가지고 있다는 것을 설명하는 것일 수도 있습니다. 우리는 이것도 정규화해보려고 합니다.\nRPKM RPKM은 single-end RNA-seq용으로 제작되었습니다. 먼저 사자성어 풀이하듯 각 알파벳의 의미를 먼저 살펴보겠습니다. Reads Per Kilobase per Millions mapped reads\n그러면 이게 무슨 뜻이냐\u0026hellip;하면 전체 유전자의 길이를 Kilobase(=1000 base pair)로 정규화했을 때 전체 reads 중에서 해당 gene에 mapping된 reads들을 말합니다. 그런데 이 수는 너무 적기 때문에 106을 곱해주게 됩니다.\n즉 FPKM은 total (1)reads에서 gene에 매핑된 리드들 나눈 값, (2) gene의 전체 길이를 1000으로 나눈 값, (3)106을 곱해주면 됩니다.\n즉, gene 단위의 expression입니다.\n이해가 잘 안되신다면 직접 계산해볼까요?\n   Gene Name Rep1 Counts Rep2 Counts Rep3 Counts     A (2kb) 10 12 30   B (4kb) 20 25 60   C (1kb) 5 8 15   D (10kb) 0 0 1    먼저, (1) read depth를 정규화합니다.\n 각각의 replicate들에서 총 reads의 수를 계산합니다.     Gene Name Rep1 Counts Rep2 Counts Rep3 Counts     Total reads 35 45 106     이 Total reads를 106으로 나누어야 하는데 보기 쉽게 10으로만 나눠보겠습니다.     Gene Name Rep1 Counts Rep2 Counts Rep3 Counts     Tens of reads 3.5 4.5 10.6    따라서 이 값들은 각 replicate들에 대한 \u0026ldquo;per million\u0026rdquo; scaling factors입니다. 그러니까 우리는 각 gene의 read counts을 이 값들로 나누어야 합니다. 그러면 우리는 reads per million을 계산할 수 있는데 이를 RPM이라고 해보죠.\n   Gene Name Rep1 RPM Rep2 RPM Rep3 RPM     A (2kb) 2.86 2.67 2.83   B (4kb) 5.71 5.56 5.66   C (1kb) 1.43 1.78 1.42   D (10kb) 0 0 0.09    두 번째 단계는 (2) gene length로 정규화하는것입니다. 각 replicate의 counts를 gene length(Kilobase)로 나누면 됩니다. 쉽죠? 그러면 아래의 테이블이 나오게 됩니다.\n   Gene Name Rep1 RPKM Rep2 RPKM Rep3 RPKM     A (2kb) 1.43 1.33 1.42   B (4kb) 1.43 1.39 1.42   C (1kb) 1.43 1.78 1.42   D (10kb) 0 0 0.009    자 그러면 우리는 RPKM을 가지게 되었습니다.\n정리해볼까요?\n우리는 depth와 gene length을 정규화하지 않은 데이터를 가지고 있었습니다.\n   Gene Name Rep1 Counts Rep2 Counts Rep3 Counts     A (2kb) 10 12 30   B (4kb) 20 25 60   C (1kb) 5 8 15   D (10kb) 0 0 1    하지만 우리는 이제 각각의 sequencing depth와 각각의 gene length에 대해 정규화해서 각각의 replicate와 각각의 gene에 대한 RPKM 데이터를 가지게 되었습니다.\n   Gene Name Rep1 RPKM Rep2 RPKM Rep3 RPKM     A (2kb) 1.43 1.33 1.42   B (4kb) 1.43 1.39 1.42   C (1kb) 1.43 1.78 1.42   D (10kb) 0 0 0.009    FPKM RPKM과 유사한 이름을 가지고 있는 FPKM은 Fragment Per Kilobase of transcript per Million mapped reads의 약자입니다. paired-end로 RNA-seq을 하면 하나의 fragment에서 2개의 read가 나옵니다. (RPKM의 무조건 2배가 되는건 아닙니다) 이는 transcript 관점의 expression으로 볼 수 있습니다.\nRPKM과 FPKM의 차이점은 FPKM은 두개의 reads가 하나의 fragment에 mapping된다는 점을 고려한다는 것입니다.\nTPM TPM은 Transcripts Per Million의 약자로 FPKM, RPKM과 유사한 개념이지만 transcript length의 분포까지 포함한 개념이라고 합니다.\nTPM을 계산하는 방법 아래와 같습니다.\nRPKM / Total RPKM * 10^6\n흠.. 같이 봐볼까요?\n   Gene Name Rep1 Counts Rep2 Counts Rep3 Counts     A (2kb) 10 12 30   B (4kb) 20 25 60   C (1kb) 5 8 15   D (10kb) 0 0 1    먼저 (1) 각 replicate의 counts를 gene length로 나눕니다. 그러면 아래의 테이블이 나오겠죠? RPK는 Reads Per Kilobase라는걸 알 수 있습니다.\n   Gene Name Rep1 RPK Rep2 RPK Rep3 RPK     A (2kb) 5 6 15   B (4kb) 5 6.25 15   C (1kb) 5 8 15   D (10kb) 0 0 0.1    두 번째 단계로 (2) sequencing depth로 정규화하는 것입니다. 우리가 gene lengh을 정규화한 것들의 합(각 replicate read counts의 합)과 각 replicate의 RPK 수를 합하고 (원래는 10^6으로 나눠야 하지만) 10으로 나눈 Tens of RPK를 사용할 것입니다.\n   Gene Name Rep1 RPK Rep2 RPK Rep3 RPK     Total RPK 15 20.25 45.1   Tens of RPK 1.5 2.025 4.51    각 replicate의 counts를 Tens of RPK로 나누게 되면 TPM이 완성됩니다.\n   Gene Name Rep1 TPM Rep2 TPM Rep3 TPM     A (2kb) 3.33 2.96 3.326   B (4kb) 3.33 3.09 3.326   C (1kb) 3.33 3.95 3.326   D (10kb) 0 0 0.02    그래서 이게 뭘 의미하는데? 그렇죠 계산하는 방법만 알면 다가 아니죠. 이 둘(RPKM과 TPM)이 뭐가 다른지 알아야겠지요. RPKM과 TPM을 비교해봅시다.\nRPKM    Gene Name Rep1 RPKM Rep2 RPKM Rep3 RPKM     A (2kb) 1.43 1.33 1.42   B (4kb) 1.43 1.39 1.42   C (1kb) 1.43 1.78 1.42   D (10kb) 0 0 0.009   Total 4.29 4.5 4.25    TPM    Gene Name Rep1 TPM Rep2 TPM Rep3 TPM     A (2kb) 3.33 2.96 3.326   B (4kb) 3.33 3.09 3.326   C (1kb) 3.33 3.95 3.326   D (10kb) 0 0 0.02   Total 10 10 10    위 결과들은 같은 데이터에서 나온 RPKM과 TPM 값입니다. 둘 다 gene length와 sequencing depth의 편향(bias)이 일치합니다. 하지만 각 column에 대한 정규화된 총 reads는 매우 다릅니다.\n RPKM은 각 sample마다 다른 값을 얻었습니다. TPM은 각 column마다 같은 값을 얻었습니다.  왜 이 차이가 중요한지 봐봅시다.\nComparison among TPMs Comparison among RPKMs\u0026hellip;? 감이 오시나요?\nTPM은 모든 replicate에 대하여 총 count 수가 보정되었기 때문에 각 gene에 어떤 비율로 reads가 있는지 알 수 있습니다. 예를 들어 Rep1의 gene A는 33%라고 알 수 있습니다. 그리고 이를 통해 Rep2의 gene A와 비교하였을 때 Rep1의 gene A가 Rep2의 gene A보다 약간 크다고 알 수 있습니다. 이는 Rep1의 gene A에 맵핑된 양이 Rep3의 gene A에 맵핑된 양보다 미세하게 더 많다는 걸 알 수 있습니다.\n하지만 RPKM은 각각의 replicate가 다른 total reads를 가지기 때문에 각각의 replicate의 gene을 비교하기 어렵습니다. 이 말은 각각의 gene의 reads 수를 비교하기 어렵다는 말이 됩니다.\n따라서 sample들 안에서 맵핑되는 reads의 비율을 보다 명확하게 말해주는 TPM을 사용하기를 추천드립니다.\n Reference   https://www.youtube.com/watch?v=TTUrtCY2k-w\n  https://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/\n  http://www.incodom.kr/Expression_profiling\n   "
},
{
	"uri": "https://williamjeong2.github.io/bioinformatics/",
	"title": "Bioinformatics",
	"tags": [],
	"description": "Bioinformatics",
	"content": "생물정보학에 관한 글을 올립니다.\n"
},
{
	"uri": "https://williamjeong2.github.io/blog/6-10-steps-to-become-a-data-scientist/",
	"title": "데이터 과학자(Data Scientist)가 되기 위한 10단계",
	"tags": [],
	"description": "",
	"content": "  이 포스팅은 이 글 에 있는 포스팅을 번역한 내용입니다. 오역이나 의역이 있을 수 있습니다. Original source of this posting os form this article If the original quthor requests deletion, it will be deleted immediately.    최고의 엔지니어라도 data scientist가 되는건 쉽지 않습니다. 그러나 누구에게나 어렵지는 않으며 미리 알아야 할 몇 가지가 있습니다. 이 기사에서는 이를 살펴보고 데이터과학에서 성공 하기위한 로드맵을 제공합니다.\n1. What you need to do  목표 시간 설정하라 코드를 작성하기 위해 알아야 할 지식/경험을 계획하라 훌륭한 조언을 해주는 똑똑한 사람에게 시간을 할애하라 흥미로운 데이터셋을 선택하고 검색해보아라 가장 큰 도전은 시작하는 것 이진 분류를 잊어라 : 교차 검증(cross-validation) 및 베이지안 알고리즘(Bayesian algorithms)은 훌륭한 데이터 과학자가 되는데 도움이 될 것임 데이터 과학 인터뷰에서 올바르게 질문하는 방법을 배워라  2. Problem Statement 모든 질문에 문제 서술을 영어로 작성합니다. 제가 이미 데이터 과학의 문제들을 읽을 수 있게 포스트로 작성해놨습니다.\n3. Write some code 코드를 작성하고 돌려보세요. 면접관은 코드를 보고 질문할 것입니다.\n 데이터 준비에 얼마나 시간이 걸리는지 문제를 해결하기 위해 팀에 몇명이 필요한지 무엇이 잘못 될 수 있나요? 이건 작업하기 쉬운 도구 3가지를 선택하는 힌트를 줍니다. 문제를 해결하는 데 사용할 도구를 작성하세요  4. Prepare and evaluate your answers 간결하면서 독창적인 해결방법이 있는지 확인합니다.\n5. Review your answers 답변을 수정하고 기존 framework나 tool을 사용하지 않는 이유를 스스로에게 물어봅니다.\n이러면 스스로 더 배울 필요가 있는 영역을 구분하고 향후 면접을 위해 자료를 작성하는데 도움이 됩니다.\n6. Show your solution to the problem 추가로, 해결방법을 준비해 제 3자인 면접 관련 조직에게 연락을취해 보여주고 도움을 받으면 좋습니다.\n당신의 해결방법을 노트북에 준비하고 팀과 해결방법에 대해 토의합니다.\n7. Identify Assumptions 면접관이 회사에 있다고 가정하고 해야할 일들을 정의하세요. 다른 사람들로부터 스스로 돋보이기 위해서는 이 가정은 생략/타협하면 안됩니다.\n8. Identify Solutions 팀이 예상한 것들과 해야할 일들을 확인해보세요. 시간이 있다면 이러한 것들을 검토해보는 것도 좋습니다.\n9. Use the Pareto Principle 통계의 개념 인 파레토 분포 법칙을 사용하세요. 이 경우 분포는 독립 이벤트 중 가장 좋은 결과를 제공할 가능성이 높습니다.\n10. Build a model 모든 질문에는 가지고 있는 데이터에 맞는 답이 있습니다. 강력한 해결방법을 정의하고 적용하는데 시간을 투자하여 향후 있을 면접에서 입증하세요.\n프로그래밍 경험은 데이터 과학에서 매우 중요합니다. 코드없이 코드를 실행하고 버그를 찾아야합니다. 이 경우 코드가 없는 것보다 더 나쁜 코드는 없습니다. 코드를 다시 작성하고 버그를 수정하라는 메시지가 보인다면 data scientist에게 문의하세요.\n프로그래밍 언어의 차이는 문화차이보다 중요하지 않습니다. 두 그룹의 learning curve가 당신이 좋은 기회를 갖기 위해 어디에 집중해야 하는지 고르는 데 도움이 될 겁니다.\n"
},
{
	"uri": "https://williamjeong2.github.io/blog/",
	"title": "Devlog",
	"tags": [],
	"description": "Devlog",
	"content": ""
},
{
	"uri": "https://williamjeong2.github.io/bioinformatics/03-which-reference-genome-should-i-use/",
	"title": "어떤 reference genome을 사용해야 할까?",
	"tags": [],
	"description": "",
	"content": "들어가기 전에  이 포스팅은 Tutorial: Which human reference genome should I use? 에 있는 포스팅을 번역한 내용이 포함되어있습니다. 오역이나 의역이 있을 수 있습니다. 지적해주시면 확인 후에 정정하겠습니다. Original source of this posting is form Tutorial: Which human reference genome should I use? If the original author requests deletion, it will be deleted immediately.   \u0026ldquo;어떤 reference genome을 선택해야 하는가?\u0026ldquo;는 biostas에서 나오는 상위권 질문들중 하나입니다. 이 질문에 대한 답은 꽤 쉬워보입니다: 가장 최신의 major 버전(GRCh38)을 가져오는 것입니다.(Genome Reference Consortium)\n그러나 genome 파일을 다운로드 하러가기 전에 다음 질문들이 명확해야 합니다:\n 이전 버전을 사용해야 하는 이유는 무엇인가? reference fasta 에는 어떤 서열정보가 포함되어 있는가? 최신 마이너 버전의 사용은 어떤가? 정렬(alignment)을 위해 reference fasta를 준비하려면 어떤 단계들이 필요한가?  1. 이전 버전을 사용해야 하는 이유는 무엇인가? 시작하기 전에 실험에 사용할 데이터베이스를 확인합니다. 최근 assembly에 대한 데이터 접근이 가능한지? 해당 데이터를 아직 사용할 수 없는 경우 데이터를 최신 버전으로 옮기려면 얼마나 큰 노력을 기울여야 하는지?\n2. reference fasta 에는 어떤 서열정보가 포함되어 있는가? 최신 메이저 릴리즈 파일은 다음과 같습니다: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.28_GRCh38.p13 (2020/01/14 기준)\n서열은 GCA_000001405.28_GRCh38_genomic.fna.gz 에 있습니다.\n이 파일은 다음의 서열정보를 포함합니다.\n chromosomes 1-22, X, Y sequences that can be asigned to one chromosome, but not to an exact position or orientation (unlocalized sequences) sequences that cannot be assigned to any chromosome (unplaced sequences) the mitochondrial genome sequences that provides an alternate representation of a locus (alernate locus)  (1)-(3) build together the so-called Primary Assembly.\n3. 최신 마이너 버전의 사용은 어떤가? .p\u0026lt;version-number\u0026gt; 라고 나타나는 마이너 버전을 알 수 있을 것입니다. 최신 버전은 GRCh38.p13.입니다. (2020/01/14 기준) 그런데 제가 왜 이 버전의 링크를 제공하지 않았을까요?\n마이너 버전의 서열들은 메이저 버전에서 untouch 되었습니다. 대신에 패치라고 불리는 서열정보가 추가되었습니다(여기서 p가 유래됨.). 이런 패치는 기존 서열의 수정일 수 있으며 다음 메이저 릴리즈 버전의 기본 assembly로 통합될 것입니다. 또는 다음 메이저 릴리즈에서 \u0026ldquo;alternate loci\u0026quot;라고 하는 새로운 서열을 나타내기도 합니다.\n이 FAQ 에서 패치에 대한 자세한 내용을 읽을 수 있습니다.\n따라서 우리가 특별한 이유가 있지 않은 한, 우리는 정렬(alignment)를 위해 primary assembly 및 mitochondrial genome의 서열을 사용해야 합니다. 그 이유는 다음 챕터에서 말해드리겠습니다.\n4. 정렬(alignment)을 위해 reference 패스트를 준비하려면 어떤 단계들이 필요한가?  이 부분에 설명하는 대부분의 내용들은 Heng Li 의 블로그 포스트에서 영감을 받았습니다. (Heng Li는 우리가 잘 알고있는 bwa 와 samtools 의 개발자입니다.)\n 위에 링크된 reference sequence는 다음 세 가지 이유로 정렬(alignment)에 사용할 준비가 되어있지 않습니다:\n loci의 alternate represnetation이 포함됩니다. 이것들은 primary assembly와 매우 유사한데, 그렇기 때문에 대부분의 정렬(alignment)에서는 reads 위치를 알지 못하고 mapping 품질이 매우 낮습니다(variant calling에는 좋지 않다는 걸 의미합니다.). 염색체 Y에는 유사 염색체 X에 위치한 영역의 복제인 pseudo-autosomal region(PAR)이 있습니다. 이것 또한 정렬(alignment)에서 read의 위치를 알지 못합니다. 서열들이 1 이라는 이름 대신에 CM000663.2 라는 GeneBank Accesion Numbers 를 가지고 있습니다.  (1)에서 보여지는 불분명한 mapping은 (2)에서 패치 서열에서도 유효합니다. 이건 우리가 정렬(alignment)을 할 때 최신 마이너 버전을 사용할 필요가 없는 이유입니다.\n그래서 우리는 이렇게 해야합니다:\n GRC로부터 제공되는 서열들의 서브셋을 구축 염색체 Y의 PAR을 표시 서열 이름 바꾸기  이러한 일들을 하기 위해서 우리는 몇가지 파일들이 필요합니다:\n 서브셋을 구축하고 서열 이름을 바꾸기 위해 GCA_000001405.28_GRCh38.p13_assembly_report.txt PAR을 표시하기 위해 par_align.gff  GRC로부터 제공되는 서열들의 서브셋 구축 reference sequence 를 다운로드 한 후에 압축을 풀고 samtools faidx 로 인덱스한다:\n$ samtools faidx GCA_000001405.28_GRCh38.p13_genomic.fna GCA_000001405.28_GRCh38.p13_assembly_report.txt 에서 primary assembly들과 mitochondrial genome의 이름들을 추출해야 합니다. 많은 bioinformatic tool들이 서열들이 정리되었다 여깁니다. 따라서 현재 이름을 나중에 사용하려는 서열 이름으로 정렬해야 합니다.\n$ sort -k1,1V GCA_000001405.28_GRCh38.p13_assembly_report.txt|awk -v FS=\u0026#34;\\t\u0026#34; \u0026#39;$8 == \u0026#34;Primary Assembly\u0026#34; || $8 == \u0026#34;non-nuclear\u0026#34; {print $5}\u0026#39; \u0026gt; subset_ids.txt 이 목록을 사용하여 서열의 서브셋을 구축할 수 있습니다.\n염색체 Y의 PAR을 표시 par_align.gff 에는 PAR이 X염색체에 있고 그것에 맞먹는 것들이 Y 염색체에 있다는 정보가 들어있습니다. 파일을 열고 각 라인에서 Target 키워드를 찾아보세요. 값은 우리가 마스크하고 싶은 Y 염색체의 위치입니다. 이렇게 하려면 이러한 값을 가진 bed 파일을 우리가 만들어야 합니다(주의 : gff 는 1-based position이며 bed 는 0-based입니다). 우리는 이렇게 하면 됩니다.\n$ cat parY.bed CM000686.2 10000 2781479 CM000686.2 56887902 57217415 bed 파일을 가져오는 한 줄짜리 코드:\n$ sed -E \u0026#39;s/.*Target=([^;]+).*/\\1/g\u0026#39; par_align.gff|awk -v OFS=\u0026#34;\\t\u0026#34; \u0026#39;$0 !~ \u0026#34;^#\u0026#34; {print $1, $2-1, $3}\u0026#39; \u0026gt; parY.bed bedtools 를 가지고 표시할 수도 있습니다:\n$ bedtools maskfasta -fi GRCh38_subset.fa -bed parY.bed -fo GRCh38_subset_masked.fa 서열 이름 바꾸기 최근에는 각각의 서열들의 헤더는 다음과 같습니다:\n\u0026gt; CM000663.2 우리가 좋아하는 것은 이렇게 하는 겁니다:\n\u0026gt;1 CM000663.2 NC_000001.11 chr1 첫 공백까지 오는 건 모두 ID가 됩니다. 그 뒤에 오는건 정보가 됩니다.\n$ awk -v FS=\u0026#34;\\t\u0026#34; \u0026#39;NR==FNR {header[\u0026#34;\u0026gt;\u0026#34;$5] = \u0026#34;\u0026gt;\u0026#34;$1\u0026#34; \u0026#34;$5\u0026#34; \u0026#34;$7\u0026#34; \u0026#34;$10; next} $0 ~ \u0026#34;^\u0026gt;\u0026#34; {$0 = header[$0]}1\u0026#39; GCA_000001405.28_GRCh38.p13_assembly_report.txt GRCh38_subset_masked.fa \u0026gt; GRCh38_alignment.fa 인덱싱 이제 GRCh38_alignment.fa 는 정렬에 사용할 준비가 되었습니다. 다른 tool들이 필요로 하기 때문에, 저는 이 파일을 samtools faidx 로 인덱스 하기를 추천합니다. 또한 사용하려는 alignment tool에 설명된 방식으로 인덱싱 해야합니다. 예를 들어 bwa 라면 : bwa index GRCh38_alignment.ga\n "
},
{
	"uri": "https://williamjeong2.github.io/bioinformatics/4-fastq-format/",
	"title": "FastQ 란?",
	"tags": [],
	"description": "",
	"content": " FastQ 포맷에 대한 공식 문서는 여기에서 볼 수 있습니다.\n FastQ format 무엇인가 FastQ(이하 fastq) 포맷은 시퀀스 분석에서 널리 사용되는 포맷입니다. 많은 분석 툴에서 FastA 보다 더 많은 정보를 포함하기 때문에 fastq 포맷을 요구합니다.\nfasta포맷과 유사한 포맷이지만 quality score같은 syntax가 다릅니다.\n 첫 번째 라인은 @로 시작합니다. (\u0026gt;가 아님!)  이하 자세한 내용은 아래에서..   두 번째 라인은 시퀀스를 나타냅니다. 세 번째 라인은 + 로 시작되며, 똑같은 시퀀스 identifier를 가지지만 더이상 사용하지 않습니다. 따라서 + 만 남습니다. 네 번째 라인은 각 시퀀스에 대한 Quality score를 의미합니다.  첫 번째 라인의 fastq 시퀀스 identifier는 보통 각각의 포맷이 붙습니다. 즉, 첫 번째 라인 속 각각의 정보들이 시퀀스와 위치정보를 의미합니다.\n@HW-ST911:111:C0N4WACSS:5:1101:2249:2216:1:N:0:TTAGGC CGATC:@@@FF  HW-ST911  the unique instrument name   111  the run id   C0N4WACSS  the flowcell id   5  flowcell lane   1101  tile number within the flowcell lane   2249  \u0026lsquo;x\u0026rsquo;-coordinate of the cluster within the tile   2216  \u0026lsquo;y\u0026rsquo;-coordinate of the cluster within the tile   1  the member of a pair, 1 or 2 (paired-end or mate-pair reads only)   N  Y if the read is filtered, N otherwise   0  0 when none of the control bits are on   TTAGGC CGATC  index sequence    FastQ 포맷을 사용하는 소프트웨어? 대표적인 예는 아래와 같습니다.\n Aligners  Bowtie, Tophat2   Assemblers  Velvet, Spades   QC tools  Trimmomatic, FastQC    FastQ 파일이 어떻게 만들어질까? Sequencers는 FastQ 포맷을 표준으로 만들어집니다. 또한, 몇몇 다른 파일 포맷(BAM, SFF, HDF5)으로부터 만들어지기도 하지만 어떤 시점에서는 모두 fastq 형태였습니다.\n Reference  https://learn.gencore.bio.nyu.edu/ngs-file-formats/fastq-format/  "
},
{
	"uri": "https://williamjeong2.github.io/blog/7-docker-out-of-disk-space/",
	"title": "docker를 운영하다가 용량 부족 문제를 겪을 때.",
	"tags": [],
	"description": "",
	"content": "들어가면서 docker를 사용하다 보면 많은 이미지와 컨테이너를 다루게 됩니다. 따라서 docker 기본 경로에는 많은 용량이 누적되게 되고, 물리적인 용량 부족 문제를 겪게 됩니다. 용량 부족문제가 아니게 되더라도 사용하지 않는 이미지와 컨테이너를 삭제함으로 여유공간을 더욱 확보할 수 있게 됩니다. 이에 따라 해결방법을 알아보겠습니다.\n해결방법 해결 방법에는 몇 가지가 있습니다.\n1. 안쓰는 이미지, 컨테이너 삭제 컨테이너와 이미지를 rm 또는 rmi 명령어를 사용해서 지웠다고 하더라도 docker 경로의 용량변화는 없게 됩니다. 그럴 경우 아래의 명령어로 안쓰는 이미지와 컨테이너를 삭제 할 수 있습니다. 아래의 명령어에 대한 자세한 내용은 docker docs 를 참고해주세요.\ndocker system prune -a -f -a -f 옵션에 대한 설명입니다.\n -a - 컨테이너에 연결되지 않은 사용하지 않는 모든 이미지들 제거. -f - 프롬프트로 확인을 하지 않음.  2. docker 기본 경로 변경 💡 docker 기본 경로를 변경하면 기존 경로에 있던 이미지와 컨테이너들은 삭제됩니다. 미리 백업해두시길 바랍니다. docker가 이미지, 컨테이너를 저장하고 기타 파일을 저장하기 위해 사용하는 경로는 /var/lib/docker/ 입니다. 이 경로를 넉넉한 용량을 가진 디렉토리로 변경해주면 용량 문제를 벗어날 수 있겠죠?\n🙋🏻‍♂️ 아래의 방법은 도커 설정 파일을 통해 변경하는 방법입니다. /lib/systemd/system/docker.service 파일을 수정하는 방법도 있지만 아래의 방법을 권장합니다.\n daemon.json 파일을 만들어줍니다. 이 파일은 기본적으로 존재하지 않습니다. 따라서 아래의 경로에 만들어 주어야 합니다.\nvi /etc/docker/daemon.json 변경될 경로를 넣어줍니다. 이렇게 되면 도커가 실행할 때 저 파일을 읽어 path를 결정합니다.\n{ \u0026#34;graph\u0026#34;: \u0026#34;/home/path\u0026#34; # 원하는 경로로 설정 } json 파일을 저장하고 도커를 재시작합니다.\nsudo systemctl restart docker # systemctl 명령어가 사용되지 않을 경우 sudo service docker start 컨테이너를 실행하고 도커를 확인(ps -ef | grep docker)하면 아래처럼 변경된 경로로 나오는 것을 확인할 수 있습니다.\nroot 21800 19983 0 10:52 ? 00:00:00 docker-containerd-shim -namespace moby -workdir /home/ykkim/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/8adc00f3bbdd4fd44110f42a7b25e8598019963a83b6b8d3d29266c426701db8 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root /var/run/docker/runtime-runc 이렇게 해서 docker 기본 경로를 변경하게 됩니다.\n"
},
{
	"uri": "https://williamjeong2.github.io/blog/8-nas-network-drive-mount-on-ubuntu/",
	"title": "우분투에 NAS 마운트",
	"tags": [],
	"description": "",
	"content": "들어가면서 우리는 NAS를 사용하면서 데스크탑에 저장할 수 없는 대용량의 자료들을 저장하고는 합니다. 보통 백업의 용도로 사용되는데, 가끔은 외장하드처럼 마운트해서 사용해야 할 때가 있죠. 그래서 여러가지 접속 방법을 사용하여 자신의 PC에 있는 드라이브 처럼 사용할 수 있습니다. 윈도우는 검색하면 많이 나오는데 우분투의 경우에는 많이 없는 것 같아서 기록을 하게 되었습니다.\n환경 알아야 할 정보들:\n NAS IP NAS access ID NAS access PW 마운트할 nas 경로 마운트할 local 경로  Methods 1. 패키지 설치 마운트를 하기 위한 패키지 설치 단계로 cifs-utils를 설치해주어야 합니다.\nsudo apt-get install cifs-utils 2. 마운트 하기 위한 폴더 생성 NAS를 현재 우분투의 경로에 마운트를 해 주어야 하는데, 그러기 위해 폴더를 생성해줍니다.\nmkdir /mnt/nas-drive # /mnt/nas-drive 루트 경로에 추가하기 위해서는 sudo 권한이 필요할 것이며, # 자신의 디렉토리에 폴더를 생성해서 마운트도 가능합니다. 3. 네트워크 드라이브 연결 (마운트) 아래와 같은 형식으로 입력을 해주어야 합니다. 마지막에 위치하는 vers=1.0 을 입력해주어야 저는 에러가 나지 않더라구요.\nsudo mount -t cifs //{NAS drive IP}/{NAS directory path} {local path} -o user=\u0026#39;NAS ID\u0026#39;,password=\u0026#39;NAS PW\u0026#39;,rw,vers=1.0 예를 들어:\n NAS IP : 111.11.11.111 NAS access ID : admin NAS access PW : admin 마운트할 nas 경로 : /home 마운트할 local 경로 : /mnt/nas-drive  라는 환경이라면\nsudo mount -t cifs //111.11.11.111/home /mnt/nas-drive -o user=\u0026#39;admin\u0026#39;,password=\u0026#39;admin\u0026#39;,rw,vers=1.0 가 되겠죠?\n4. 자동 마운트 등록 4번을 진행하지 않는다면 재부팅 후에는 마운트가 끊어집니다. 계속 연결이 되어야 한다면 fstab 에 등록을 해주어서 부팅할 때마다 마운트 하도록 하면 됩니다.\nsudo vim /etc/fstab //111.11.11.111/home /mnt/nas-drive cifs user=\u0026#39;admin\u0026#39;,password=\u0026#39;admin\u0026#39;,rw,vers=1.0\t0\t0  "
},
{
	"uri": "https://williamjeong2.github.io/blog/9-python-funtions/",
	"title": "보통 잘 모르는 파이썬 내장함수 3가지",
	"tags": [],
	"description": "",
	"content": "파이썬의 기본을 한 번 끝낸 후, 조금 더 심화된 파이썬 문법을 필요로 한다면 배워볼 수 있는 문법들입니다. 중급 문법들은 파이썬을 조금 더 쉽게 작성할 수 있도록 도와주고 불필요한 반복을 없애주죠.\n이번 시간에는 map, filter, reduce에 대해 배워볼건데, 이 3가지 함수들은 list를 다루는 함수입니다. 물론 기본 문법에서 배운 것처럼 이 3가지 함수를 사용하지 않아도 코딩하는 것에는 문제가 없습니다. 하지만 저의 경우에는 아래의 3가지 함수를 통해 반복문을 덜 사용하게 되었고, 불필요한 함수를 따로 만들어줄 필요가 없어서 편했습니다.\n자 그러면 시작해볼까요?\n map map 은 리스트의 각 요소들을 지정된 함수로 처리하는 기능을 합니다. 쉽게 말하면 A라는 함수가 있고 list B가 있다면 A함수를 B로 수행한 결과를 돌려주는 거라고 할 수 있습니다.\n먼저 for 반복문을 사용하여 정수가 저장된 리스트를 제곱하고 2로 나누어 볼까요?\na = [1, 2, 3, 4] result = [] for i in range(len(a)): result.append(a[i] ** 2 / 2) print(result) 1, 2, 3, 4의 정수 리스트를 받아 제곱을 해주고 2로 나눠주는 코드입니다. 간단하죠? 실행 결과는 다음과 같습니다.\n 결과 : [0.5, 2.0, 4.5, 8.0]\n 이 예제를 map 함수를 사용해볼까요?\na = [1, 2, 3, 4] print(list(map(lambda x: x**2/2, a))) 똑같이 4개의 정수를 각 element를 받아 제곱을 해주고 2로 나눠주는 코드입니다. map 함수 앞에서 list 함수를 통해 list 자료형으로 변환하는 이유는 map 함수의 반환이 list가 아니기 때문인데요. Iterator 로 반환하는 값을 list로 변환하는 것입니다.(Iterator에 대해서는 다음에 따로 글을 써보겠습니다.)\n filter 정의 : 무엇을 걸러내다.\n실제 filter 함수의 쓰임도 정의와 같습니다. filter 은 A라는 함수에 대해 리스트 B의 element 중 참에 해당하는 값을 돌려주는 것이라고 할 수 있습니다.\na = [-3, -2, -1, 0, 1, 2, 3] print(list(filter(lambda x: x\u0026gt;0, a))) -3에서 3까지의 정수중에서 0보다 큰 값을 돌려주는 코드입니다. 참 쉽죠?\n이 방법이 괜찮은데? \n하지만 꼭 이 방법만을 써야하는건 아닙니다. 우리에게는 list comprehension 이 있습니다.\nmap 함수를 list comprehension으로 구현해 볼까요?\na = [1, 2, 3, 4] print([x**2/2 for x in a]) 오히려 더 간결한 것 같기도 하고..\nfilter 함수도 마찬가지입니다.\na = [-3, -2, -1, 0, 1, 2, 3] print([x for x in a if x\u0026gt;0]) 이처럼 방금 배운 map과 filter가 마음에 들지 않으면 list comprehension을\u0026hellip;쓸 수도 있습니다.\n reduce reduce 는 원래는 내장함수였는데 python 3부터 내장함수에서 빠지고 functools에서 가져와야 합니다.\nreduce에 대한 원리는 그림 한장으면 끝납니다.\n아이큐 테스트같지만 1부터 5까지 차례대로 더하는 거라는 걸 알 수 있겠죠? 수식으로 표현해 본다면 다음과 같습니다.\n((((1+2)+3)+4)+5) 코드로 작성해 보면 아래와 같습니다.\nfrom functools import reduce a = [1, 2, 3, 4, 5] print(reduce(lambda x, y: x+y, a)) reduce 함수의 경우에는 list comprehension로 대체할 수 없습니다. 이유는 reduce 함수는 2 element가 입력으로 들어가게 되는데 list comprehension은 2가지 입력을 받지 못하기 때문입니다.\n"
},
{
	"uri": "https://williamjeong2.github.io/blog/10-docker-run-vs-cmd-vs-entryporint/",
	"title": "🐳 Dockerfile 명령어 RUN, CMD, ENTRYPOINT 차이",
	"tags": [],
	"description": "",
	"content": "Dockerfile 을 작성하다 보면 RUN, CMD, ENTRYPOINT 차이를 알아야 할 경우가 생기게 됩니다. 세 가지 명령어를 잘 모르고 사용하게 된다면 곤란한 상황을 겪게 될수도있습니다.\nTL;DR   RUN\n이미지 생성시 새로운 레이어를 생성하여 명령어를 실행하게 됩니다. 보통 아래와 같은 방식으로 활용하게 됩니다.\nRUN apt-get install -y curl # 또는  RUN chmod -R 777 /tmp   CMD\ndefault 명령이나 파라미터를 설정할 수 있습니다. 우리가 도커 이미지를 사용하여 docker run 명령어로 컨테이너를 생성할 경우 생성 후에 실행될 커맨드를 입력해주지 않는다면, CMD 명령어를 사용하여 작성된 커맨드가 기본으로 실행됩니다. 또한 바로 다음에 설명할 ENTRYPOINT의 기본 파라미터를 설정할 수도 있습니다. 즉, CMD 는 컨데이터를 실행할 때 기본으로 사용되는 명령어를 설정하는 것입니다.\n  ENTRYPOINT\ndocker run 명령어로 컨테이너를 생성 후 실행되는 명령어입니다.\n   RUN 보통 이미지에 새로운 패키지를 설치하거나 명령어를 실행시킬 경우 사용됩니다.\nFROMubuntu:18.04 RUN apt-get update RUN apt-get install -y python3 python3-pip wget git less neovim RUN pip3 install pandas RUN 명령은 실행할 때마다 레이어가 생성됩니다. 따라서 RUN  명령어 하나에 통합해준다면 보다 깔끔하게 레이어를 관리할 수 있습니다.\n# example FROMubuntu:18.04 RUN apt-get update \\  \u0026amp;\u0026amp; apt-get install -y python3 python3-pip wget git less neovim \\  \u0026amp;\u0026amp; pip3 install pandas  CMD docker run 명령어 실행 시 실행 될 기본 명령어를 설정하거나, 아래에 있는 ENTRYPOINT 의 기본 명령어 파라미터를 설정할 때 사용됩니다. CMD 명령어는 보통 컨테이너를 실행할 때 사용할 기본 명령어를 설정하는 것입니다.\n CMD [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] (exec form, preferred) CMD [\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] (sets additional default parameters for ENTRYPOINT in exec form) CMD command param1 param2 (shell form)  FROMubuntu:18.04 CMD echo \u0026#34;Hello\u0026#34; 위와 같이 작성하여 만들어진 이미지를 docker run (옵션 x) 명령어 실행 시 CMD 명령어가 실행되어 \u0026ldquo;Hello\u0026rdquo; 를 출력하게 됩니다.\n하지만, 두 번째 줄에 작성한 CMD echo \u0026quot;Hello\u0026quot; 와 별개로 docker run -it \u0026lt;image_name\u0026gt; echo \u0026quot;Hello world\u0026quot; 명령어를 주게 되면, dockerfile 에서 작성한 \u0026ldquo;Hello\u0026quot;는 무시되고 \u0026ldquo;hello world\u0026quot;를 출력하게 됩니다.\nCMD는 여러 번 dockerfile에 작성할 수 있지만, 가장 마지막에 작성된 CMD 만이 실행(override)됩니다.\n ENTRYPOINT docker run 명령어로 컨테이너를 생성 후 실행되는 명령어입니다.\n  ENTRYPOINT [“executable”, “param1”, “param2”] (exec form, preferred)\n  ENTRYPOINT command param1 param2 (shell form)\n  CMD 와의 차이를 쉽게 설명하자면, ENTRYPOINT 는 docker run 뒤에 명령어 작성과 무관하게 실행되는 명령어입니다.\nFROMubuntu:18.04 ENTRYPOINT [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hi\u0026#34;] CMD echo \u0026#34;Hello\u0026#34; $ docker run -it \u0026lt;image_name\u0026gt; Hi Hello $ docker run -it \u0026lt;image_name\u0026gt; Mother Hi Mother 차이를 아시겠나요?\n   그렇다면, 변수를 사용하기 위해서는?  FROMubuntu:18.04 ENTRYPOINT echo $HOME $ docker run -it \u0026lt;image_name\u0026gt; /home  "
},
{
	"uri": "https://williamjeong2.github.io/bioinformatics/paper-review/",
	"title": "Paper Review",
	"tags": [],
	"description": "PaperReview",
	"content": "생물정보학에 관한 논문 리뷰\n"
},
{
	"uri": "https://williamjeong2.github.io/404.html",
	"title": "Whoops! Page not found",
	"tags": [],
	"description": "This is a 404 page",
	"content": "That page can\u0026rsquo;t be found.\nOur latest content is on the homepage.\nPhoto by Aron Visuals on Unsplash"
},
{
	"uri": "https://williamjeong2.github.io/blog/4-weekly-archive-1/",
	"title": "🔖한 주간 본 영상, 글 아카이브 #1",
	"tags": [],
	"description": "",
	"content": "🗓 2019.12.02 ~ 2019.12.08\n 📃 포트스\n깃허브(GitHub)로 취업하기\n 개발자라면 다 하나씩은 가지고 있을만한 github 계정을 어떻게 관리해야 하는지, 커밋의 올바른 방법, readme.md 작성법, 오픈소스 기여하기 등을 다루고 있다. github 사용을 위해 약속한 사항들을 무시하고 사용하고 있었다는 생각이 들었다. 지금이라도 어느정도 (commit message rule과 같은) 정해진 틀을 갖추고 이용해야겠다.   "
},
{
	"uri": "https://williamjeong2.github.io/blog/5-weekly-archive-2/",
	"title": "🔖한 주간 본 영상, 글 아카이브 #2",
	"tags": [],
	"description": "",
	"content": "📄 포트스\n웹 서비스 출시 전 확인사항\n 웹 서비스를 개발하는 개발자는 아니지만 서비스 오픈 전 체크해야할 사항들에 대해서 이야기 하고 있다. 로그, 서버\u0026amp;리눅스, 데이터베이스 영역에서 놓칠 수 있는 설정들을 확인하고 대응할 수 있다.  나는 어떻게 공부했는가?\n \u0026lsquo;성장하는 개발자를 위한 팁\u0026rsquo;이라는 부제가 내 눈을 사로잡았다. 이 포스트는 성장하지 못하는 개발자들이 보다 효율적으로 성장할 수 있는 개발공부 가이드를 제공한다. 기억에 남는 부분이 마무리의 내용이었는데, 남들이 공부했던 방식을 그대로 따라가지 말고 자신에게 맞는 공부법을 찾으라는 말이었다. 개발자 뿐만 아니라 많은 사람들은 자기만의 패턴과 시간을 가지고 있다. 남들이 옳다고 하는 방법이 항상 옳지는 않기 때문에 자신의 방식을 찾을 필요가 있다는 말에 동감한다.   🗞️ 소식\n세계 최대 기업용 메신저 슬랙, 국내 상륙한다\n 사실 이미 쓸사람은 다 쓰고 있을거라고 생각하는데 국내 상륙한다고 해도 한글화와 고객지원 서비스정도라고 생각된다. MS사의 Teams이랑 경쟁을 어떤식으로 할 지 궁금하다. 사실 office365는 Teams을 기본으로 탑재하고 있기 때문에 비용 측면에서 유리한데 office와의 연동도 좋기 때문이다.   "
}]